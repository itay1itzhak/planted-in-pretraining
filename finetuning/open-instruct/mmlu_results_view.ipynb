{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before using:Must run MMLU evaluation for the required models using open-instruct MMLU evaluation script (finetuning/open-instruct/eval/mmlu/run_eval_local.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_accuracies(model_accuracies,baselines=\"olmo\"):\n",
    "    # Initialize an empty DataFrame\n",
    "    data = []\n",
    "\n",
    "    # Loop through the dictionary to populate the DataFrame\n",
    "    for model_name, results in model_accuracies.items():\n",
    "        for step, accuracy in results:\n",
    "            data.append((model_name, step, accuracy))\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Model', 'Steps', 'Accuracy'])\n",
    "\n",
    "    # Set the plot theme\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    # Use a different color palette for the models\n",
    "    palette = sns.color_palette(\"husl\", len(model_accuracies))\n",
    "    sns.lineplot(data=df, x='Steps', y='Accuracy', hue='Model', marker='o', palette=palette, linewidth=2.5)\n",
    "\n",
    "    # Add horizontal lines for the baselines\n",
    "    if baselines == \"olmo\":\n",
    "        plt.axhline(y=28.6, color='black', linestyle='--', label='OLMo (base) - 28.6')\n",
    "        plt.axhline(y=47.3, color='blue', linestyle='--', label='OLMo-SFT - 47.3')\n",
    "    elif baselines == \"t5\":\n",
    "        # 0-shot\n",
    "        #plt.axhline(y=25.9, color='black', linestyle='--', label='T5 (base) - 25.9')\n",
    "        #plt.axhline(y=55.1, color='blue', linestyle='--', label='Flan-T5 - 55.1')\n",
    "        # 5-shot \n",
    "        plt.axhline(y=23.0, color='black', linestyle='--', label='T5 (5-shot) - 23.0')\n",
    "        plt.axhline(y=54.6, color='blue', linestyle='--', label='Flan-T5 (5-shot) - 54.6')\n",
    "\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Number of Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy during Training')\n",
    "\n",
    "    # Adjust the legend\n",
    "    #plt.legend(title='Model and Baselines')\n",
    "    #plt.legend(title='Model and Baselines', bbox_to_anchor=(1.05, 1.4), loc='upper left')\n",
    "    #plt.legend(title='Model and Baselines', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14)\n",
    "    #plt.legend(title='Model and Baselines', bbox_to_anchor=(1.5, 1.5), loc='upper left')\n",
    "\n",
    "\n",
    "    # change font size\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel('Number of Steps', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.title('MMLU Accuracy during Training', fontsize=16)\n",
    "    \n",
    "    # Adjust layout to make room for the legend\n",
    "    #plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    #plt.tight_layout()\n",
    "\n",
    "    plt.legend(title='Model and Baselines', bbox_to_anchor=(1.0, 1), loc='upper left', fontsize=14)\n",
    "\n",
    "    # Adjust layout to make room for the legend\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract MMLU Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model: T5\n",
      "output/allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4\n",
      "output/allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_1\n",
      "output/allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_2\n",
      "model_name: allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4\n",
      "model_name: allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_1\n",
      "model_name: allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_2\n",
      "\n",
      "================================================================================\n",
      "Main Category Results (Step 15000)\n",
      "================================================================================\n",
      "                                 allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4  \\\n",
      "STEM                                                                         38.30                   \n",
      "humanities                                                                   45.60                   \n",
      "other (business, health, misc.)                                              54.40                   \n",
      "social sciences                                                              56.30                   \n",
      "Model Average                                                                48.65                   \n",
      "\n",
      "                                 allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_1  \\\n",
      "STEM                                                                        36.200                          \n",
      "humanities                                                                  42.700                          \n",
      "other (business, health, misc.)                                             51.300                          \n",
      "social sciences                                                             55.300                          \n",
      "Model Average                                                               46.375                          \n",
      "\n",
      "                                 allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_2  \\\n",
      "STEM                                                                         36.60                          \n",
      "humanities                                                                   44.10                          \n",
      "other (business, health, misc.)                                              52.10                          \n",
      "social sciences                                                              55.40                          \n",
      "Model Average                                                                47.05                          \n",
      "\n",
      "                                  Mean   Std  \n",
      "STEM                             37.00  0.90  \n",
      "humanities                       44.10  1.20  \n",
      "other (business, health, misc.)  52.60  1.30  \n",
      "social sciences                  55.70  0.40  \n",
      "Model Average                    47.35  0.95  \n",
      "\n",
      "Model Averages:\n",
      "allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4: 48.7 ± 8.3\n",
      "allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_1: 46.4 ± 8.6\n",
      "allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_2: 47.1 ± 8.4\n",
      "Model Average Std in accuracy format: 0.05924768249967237\n",
      "model_name: allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4\n",
      "model_name: allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_1\n",
      "model_name: allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_2\n",
      "\n",
      "================================================================================\n",
      "Subcategory Results (Step 15000)\n",
      "================================================================================\n",
      "                  allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4  \\\n",
      "biology                                                   53.300000                   \n",
      "business                                                  73.000000                   \n",
      "chemistry                                                 36.000000                   \n",
      "computer science                                          43.700000                   \n",
      "culture                                                   58.700000                   \n",
      "economics                                                 46.800000                   \n",
      "engineering                                               41.400000                   \n",
      "geography                                                 62.100000                   \n",
      "health                                                    49.700000                   \n",
      "history                                                   60.400000                   \n",
      "law                                                       39.600000                   \n",
      "math                                                      30.500000                   \n",
      "other                                                     54.200000                   \n",
      "philosophy                                                43.900000                   \n",
      "physics                                                   37.700000                   \n",
      "politics                                                  61.300000                   \n",
      "psychology                                                57.800000                   \n",
      "Model Average                                             50.005882                   \n",
      "\n",
      "                  allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_1  \\\n",
      "biology                                                   48.200000                          \n",
      "business                                                  63.800000                          \n",
      "chemistry                                                 36.300000                          \n",
      "computer science                                          42.200000                          \n",
      "culture                                                   55.700000                          \n",
      "economics                                                 46.800000                          \n",
      "engineering                                               44.800000                          \n",
      "geography                                                 60.600000                          \n",
      "health                                                    47.800000                          \n",
      "history                                                   60.800000                          \n",
      "law                                                       36.700000                          \n",
      "math                                                      28.500000                          \n",
      "other                                                     51.500000                          \n",
      "philosophy                                                39.500000                          \n",
      "physics                                                   34.700000                          \n",
      "politics                                                  60.200000                          \n",
      "psychology                                                57.000000                          \n",
      "Model Average                                             47.947059                          \n",
      "\n",
      "                  allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_2  \\\n",
      "biology                                                   50.000000                          \n",
      "business                                                  59.700000                          \n",
      "chemistry                                                 34.000000                          \n",
      "computer science                                          42.500000                          \n",
      "culture                                                   53.900000                          \n",
      "economics                                                 45.600000                          \n",
      "engineering                                               44.800000                          \n",
      "geography                                                 62.600000                          \n",
      "health                                                    48.100000                          \n",
      "history                                                   58.200000                          \n",
      "law                                                       37.800000                          \n",
      "math                                                      28.300000                          \n",
      "other                                                     54.800000                          \n",
      "philosophy                                                43.100000                          \n",
      "physics                                                   36.600000                          \n",
      "politics                                                  60.800000                          \n",
      "psychology                                                57.800000                          \n",
      "Model Average                                             48.152941                          \n",
      "\n",
      "                  Mean       Std  \n",
      "biology           50.5  2.100000  \n",
      "business          65.5  5.600000  \n",
      "chemistry         35.4  1.000000  \n",
      "computer science  42.8  0.600000  \n",
      "culture           56.1  2.000000  \n",
      "economics         46.4  0.600000  \n",
      "engineering       43.7  1.600000  \n",
      "geography         61.8  0.800000  \n",
      "health            48.5  0.800000  \n",
      "history           59.8  1.100000  \n",
      "law               38.0  1.200000  \n",
      "math              29.1  1.000000  \n",
      "other             53.5  1.400000  \n",
      "philosophy        42.2  1.900000  \n",
      "physics           36.3  1.200000  \n",
      "politics          60.8  0.400000  \n",
      "psychology        57.5  0.400000  \n",
      "Model Average     48.7  1.394118  \n",
      "\n",
      "Model Averages:\n",
      "allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4: 50.0 ± 11.4\n",
      "allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_1: 47.9 ± 10.6\n",
      "allenai/tulu-v2-sft-mixture_t5-v1_1-xxl_lora_r128_alpha256_LR1e-4_seed_2: 48.2 ± 10.3\n",
      "Model Average Std in accuracy format: 0.08568949252933691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2357065/2289945599.py:128: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_accuracy = df.applymap(lambda x: x/100)\n",
      "/tmp/ipykernel_2357065/2289945599.py:128: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_accuracy = df.applymap(lambda x: x/100)\n"
     ]
    }
   ],
   "source": [
    "def extract_all_average_acc(model_names, main_dir=\"output/\", base_model=\"T5\", return_categories=False):\n",
    "    results = {}\n",
    "    subcat_results = {}  # New dictionary for subcategories\n",
    "    cat_results = {}     # New dictionary for main categories\n",
    "    \n",
    "    init_mmlu_score = 23.0 if base_model == \"T5\" else 28.6\n",
    "    mmlu_folder_name = \"mmlu_5_shot\" if base_model == \"T5\" else \"mmlu\"\n",
    "\n",
    "    for model_name in model_names:\n",
    "        model_dir = os.path.join(main_dir, model_name)\n",
    "        model_results = [(0, init_mmlu_score)]  # Start with the initial value\n",
    "        model_subcat_results = {}  # Track subcategory results for this model\n",
    "        model_cat_results = {}     # Track category results for this model\n",
    "        \n",
    "        print(model_dir)\n",
    "        if os.path.isdir(model_dir):\n",
    "            for step_dir in os.listdir(model_dir):\n",
    "                step_path = os.path.join(model_dir, step_dir)\n",
    "                if os.path.isdir(step_path) and step_dir.startswith(\"step_\"):\n",
    "                    metrics_file = os.path.join(step_path, \"merged\", mmlu_folder_name, \"metrics_merged.json\")\n",
    "\n",
    "                    if not os.path.isfile(metrics_file):\n",
    "                        # Sometimes the metrics_merged.json is not in the mmlu_5_shot folder, but in the mmlu folder\n",
    "                        metrics_file = os.path.join(step_path, \"merged\", \"mmlu\", \"metrics_merged.json\")\n",
    "                    if os.path.isfile(metrics_file):\n",
    "                        with open(metrics_file, 'r') as f:\n",
    "                            data = json.load(f)\n",
    "                            step_value = int(step_dir.split(\"_\")[1])\n",
    "                            \n",
    "                            # Average accuracy\n",
    "                            average_acc = round(data.get(\"average_acc\", 0) * 100, 1)\n",
    "                            model_results.append((step_value, average_acc))\n",
    "                            \n",
    "                            # Subject subcategories\n",
    "                            if \"subcat_acc\" in data:\n",
    "                                if step_value not in model_subcat_results:\n",
    "                                    model_subcat_results[step_value] = {}\n",
    "                                for subject, acc in data[\"subcat_acc\"].items():\n",
    "                                    model_subcat_results[step_value][subject] = round(acc * 100, 1)\n",
    "                            \n",
    "                            # Main categories\n",
    "                            if \"cat_acc\" in data:\n",
    "                                if step_value not in model_cat_results:\n",
    "                                    model_cat_results[step_value] = {}\n",
    "                                for category, acc in data[\"cat_acc\"].items():\n",
    "                                    model_cat_results[step_value][category] = round(acc * 100, 1)\n",
    "\n",
    "        results[model_name] = model_results\n",
    "        subcat_results[model_name] = model_subcat_results\n",
    "        cat_results[model_name] = model_cat_results\n",
    "\n",
    "    if return_categories:\n",
    "        return results, subcat_results, cat_results\n",
    "    return results\n",
    "\n",
    "def print_category_tables(subcat_results, cat_results, model_names, step_to_analyze=None):\n",
    "    \"\"\"\n",
    "    Print formatted tables of accuracies and variances for categories and subcategories.\n",
    "    \n",
    "    Args:\n",
    "        subcat_results: Dictionary of subcategory results from extract_average_acc\n",
    "        cat_results: Dictionary of category results from extract_average_acc\n",
    "        step_to_analyze: Specific step to analyze. If None, uses the last step for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    def create_table(results_dict, level=\"category\"):\n",
    "        # Initialize storage for means and variances\n",
    "        all_metrics = {}\n",
    "        \n",
    "        for model_name in results_dict.keys():\n",
    "            # If step not specified, use the last available step\n",
    "            print(f\"model_name: {model_name}\")\n",
    "            if step_to_analyze is None:\n",
    "                step = max(results_dict[model_name].keys())\n",
    "            else:\n",
    "                step = step_to_analyze\n",
    "                \n",
    "            if step not in results_dict[model_name]:\n",
    "                print(f\"Warning: Step {step} not found for model {model_name}\")\n",
    "                continue\n",
    "                \n",
    "            metrics = results_dict[model_name][step]\n",
    "            all_metrics[model_name] = metrics\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(all_metrics)\n",
    "        \n",
    "        # Sort index alphabetically\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        # Calculate mean and std across models\n",
    "        df['Mean'] = df.mean(axis=1)\n",
    "        df['Std'] = df.std(axis=1)\n",
    "        \n",
    "        # Round all values to 1 decimal place\n",
    "        df = df.round(1)\n",
    "        \n",
    "        # Format the table\n",
    "        if level == \"category\":\n",
    "            print(f\"\\n{'='*80}\\nMain Category Results (Step {step})\\n{'='*80}\")\n",
    "        else:\n",
    "            print(f\"\\n{'='*80}\\nSubcategory Results (Step {step})\\n{'='*80}\")\n",
    "            \n",
    "        # Calculate column means\n",
    "        model_means = df.mean()\n",
    "        model_stds = df.std()\n",
    "        \n",
    "        # Add model average and std row\n",
    "        df.loc['Model Average'] = model_means\n",
    "        \n",
    "        # Format the DataFrame for display\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        \n",
    "        print(df)\n",
    "        print(\"\\nModel Averages:\")\n",
    "        for column in df.columns:\n",
    "            if column not in ['Mean', 'Std']:\n",
    "                print(f\"{column}: {model_means[column]:.1f} ± {model_stds[column]:.1f}\")\n",
    "        \n",
    "        # Print the average std of the models considering accuracy in 0.XX format\n",
    "        df_accuracy = df.applymap(lambda x: x/100)\n",
    "        #print(f\"df_accuracy: {df_accuracy}\")\n",
    "        model_stds_in_accuracy_format = df_accuracy.std()\n",
    "        print(f\"Model Average Std in accuracy format: {model_stds_in_accuracy_format.mean()}\")\n",
    "    \n",
    "    # Convert the model names to the original model names\n",
    "    model_names = {model_names[key]: key for key in model_names}\n",
    "    \n",
    "    # Create and print both tables\n",
    "    create_table(cat_results, level=\"category\")\n",
    "    create_table(subcat_results, level=\"subcategory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    \"path/to/model_name\":\"T5-Tulu-Seed-0\",\n",
    "    \"path/to/model_name\":\"T5-Tulu-Seed-1\",\n",
    "    \"path/to/model_name\":\"T5-Tulu-Seed-2\",\n",
    "}\n",
    "if 'T5' in list(model_names.values())[0]:\n",
    "    base_model = \"T5\"\n",
    "else:\n",
    "    base_model = \"OLMo\"\n",
    "print(f\"base_model: {base_model}\")\n",
    "\n",
    "# First get the results using the modified extract_average_acc\n",
    "results, subcat_results, cat_results = extract_all_average_acc(model_names.keys(), main_dir=\"output/\", base_model=base_model, return_categories=True)\n",
    "\n",
    "# Then print the formatted tables\n",
    "print_category_tables(subcat_results, cat_results, model_names)\n",
    "\n",
    "# Or for a specific step:\n",
    "#print_category_tables(subcat_results, cat_results, model_names, step_to_analyze=2500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
